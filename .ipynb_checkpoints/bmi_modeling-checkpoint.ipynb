{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "980665af-c3cc-4f30-810a-a7cddd71a08e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, cross_val_score\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, mean_squared_error, r2_score\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhyperopt\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhyperopt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fmin, tpe, hp, STATUS_OK, Trials\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import xgboost as xgb\n",
    "#import lightgbm as lgb\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#import statsmodels.api as sm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import shap\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_csv('merged_dataset2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f60d034-868b-4e81-a539-31a464d9f4f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02081625-5f9d-4cc2-bb1c-271253f2f1e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df[['Weight', 'Height', 'family_history_with_overweight', 'FAF', 'FCVC', 'TUE']]\n",
    "y = df['BMI']  \n",
    "\n",
    "# Remove rows with NaN values\n",
    "X = X[~y.isna()]\n",
    "y = y.dropna()\n",
    "\n",
    "# Data Split\n",
    "# Split the data into training and test sets using train_test_split, and standardize the data using StandardScaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data Scarling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "mlp_model = MLPRegressor(\n",
    "    hidden_layer_sizes=(100, 50), \n",
    "    activation='relu',           \n",
    "    solver='adam',                \n",
    "    alpha=0.0001,                 \n",
    "    learning_rate_init=0.001,   \n",
    "    max_iter=200             \n",
    ")\n",
    "\n",
    "mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72753304-5840-478f-99e2-d48e11b57b51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5-fold validation\n",
    "cross_val_scores = cross_val_score(mlp_model, X_train, y_train, cv=5)\n",
    "cross_val_scores\n",
    "# array avaerage = final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3040deb6-8b45-49cd-9210-786afa770f1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp_model.fit(X_train, y_train)\n",
    "y_pred = mlp_model.predict(X_test)\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(mse)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d3260f-bba8-4536-b1ec-dc7211530617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameter optimization with HyperOpt\n",
    "\n",
    "np.random.seed(2024)\n",
    "\n",
    "estimate_space = {\n",
    "   'hidden_layer_sizes': hp.choice('hidden_layer_sizes', [(100,), (100, 50), (200, 100), (200, 150, 100, 50)]),\n",
    "   'alpha': hp.loguniform('alpha', np.log(1e-5), np.log(1e-2)),\n",
    "   'learning_rate_init': hp.loguniform('learning_rate_init', np.log(1e-4), np.log(1e-2)),\n",
    "   'max_iter': hp.quniform('max_iter', 200, 2000, 100)  \n",
    "}\n",
    "\n",
    "\n",
    "def objective(params):\n",
    "   # random seed\n",
    "   np.random.seed(2024)\n",
    "   \n",
    "   mlp_model = MLPRegressor(\n",
    "       hidden_layer_sizes=params['hidden_layer_sizes'],\n",
    "       activation='relu',\n",
    "       solver='adam',\n",
    "       alpha=params['alpha'],\n",
    "       learning_rate_init=params['learning_rate_init'],\n",
    "       max_iter=500,\n",
    "       random_state=2024,\n",
    "       shuffle=False  \n",
    "   )\n",
    "   \n",
    "   score = cross_val_score(mlp_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "   return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_parameter = fmin(\n",
    "    fn=objective,\n",
    "    space=estimate_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,  \n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(2024)\n",
    ")\n",
    "\n",
    "\n",
    "# Best Hyperparameters result : {'alpha': 0.00046443440409051144, 'hidden_layer_sizes': 3, 'learning_rate_init': 0.009829290091274815, 'max_iter': 900.0}\n",
    "\n",
    "# {'alpha': 0.0014053639037901015, 'hidden_layer_sizes': (200, 150, 100, 50), 'learning_rate_init': 0.006537959433035273, 'max_iter': 1900.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a045efa1-0721-4559-8ef0-9f30b68fa983",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(best_parameter)\n",
    "# {'alpha': 0.0014053639037901015, 'hidden_layer_sizes': (200, 150, 100, 50), 'learning_rate_init': 0.006537959433035273, 'max_iter': 1900.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83296f78-1537-4f08-9ed9-ce74ed8341ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hidden_layer_options = [(100,), (100, 50), (200, 100), (200, 150, 100, 50)]\n",
    "\n",
    "best_parameter['hidden_layer_sizes'] = hidden_layer_options[best_parameter['hidden_layer_sizes']]\n",
    "\n",
    "mlp_model = MLPRegressor(\n",
    "    hidden_layer_sizes=best_parameter['hidden_layer_sizes'],\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=best_parameter['alpha'],\n",
    "    learning_rate_init=best_parameter['learning_rate_init'],\n",
    "    max_iter=int(best_parameter.get('max_iter', 1600)) \n",
    ")\n",
    "\n",
    "mlp_model.fit(X_train, y_train)\n",
    "y_pred = mlp_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"MSE -> \", mse)\n",
    "print(\"R2 Score -> \", r2)\n",
    "\n",
    "#2nd try\n",
    "# MSE ->  0.03392058736342574\n",
    "# R2 Score ->  0.9994993736787691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d414f-1890-413a-aa1f-2d3444162a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Adjusted R^2\n",
    "def adjusted_r2_score(r2, n, p):\n",
    "    return 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "y_pred = mlp_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "adjusted_r2 = adjusted_r2_score(r2, len(y_test), X_test.shape[1])\n",
    "\n",
    "print(\"MSE ->\", mse)\n",
    "print(\"MAE ->\", mae)\n",
    "print(\"MAPE ->\", mape)\n",
    "print(\"R^2 Score ->\", r2)\n",
    "print(\"Adjusted R^2 Score ->\", adjusted_r2)\n",
    "\n",
    "#1st try\n",
    "# MSE -> 0.02326885745219756\n",
    "# MAE -> 0.12025047930605268\n",
    "# MAPE -> 0.42407091825945614\n",
    "# R^2 Score -> 0.9996565801652922\n",
    "# Adjusted R^2 Score -> 0.9996516269945993\n",
    "# -> Indicators improved compared to before\n",
    "# Since the MSE and R² scores are very high, it is necessary to check for overfitting\n",
    "\n",
    "#2nd try\n",
    "# MSE -> 0.03392058736342574\n",
    "# MAE -> 0.14004505564158393\n",
    "# MAPE -> 0.4980128056694918\n",
    "# R^2 Score -> 0.9994993736787691\n",
    "# Adjusted R^2 Score -> 0.9994921531068283"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8fdb5e-4461-4479-8370-f354208c39f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for train data\n",
    "y_train_pred = mlp_model.predict(X_train)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# for test data\n",
    "y_test_pred = mlp_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train MSE:\", train_mse)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "\n",
    "print(\"Train MAE:\", train_mae)\n",
    "print(\"Test MAE:\", test_mae)\n",
    "\n",
    "# If the test MSE is more than 50% larger than the training MSE, consider the possibility of overfitting\n",
    "if test_mse > train_mse * 1.5:  \n",
    "    print(\"overfitting\")\n",
    "else:\n",
    "    print(\"no significant signs of overfitting\")\n",
    "    \n",
    "    \n",
    "#2nd try\n",
    "# Train MSE: 0.02633088503157679\n",
    "# Test MSE: 0.03392058736342574\n",
    "# Train MAE: 0.1268501941880027\n",
    "# Test MAE: 0.14004505564158393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bdbe37-3f28-4d3c-ad6b-b85f1cf1e4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualization: Predicted vs Actual\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7, edgecolors='k')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual BMI')\n",
    "plt.ylabel('Predicted BMI')\n",
    "plt.title('Actual vs Predicted BMI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf4b27-4652-4731-a525-3d1f1138b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold validation\n",
    "cross_val_scores = cross_val_score(mlp_model, X_train, y_train, cv=5)\n",
    "cross_val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cee156-71f8-4d26-8316-ab438cd86b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856fe119-9548-4506-a3ff-9a727d55e6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Homebrew)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
